{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Exercises - Part 2 - 2\n",
    "\n",
    "You are now ready to get started to prepare your own spider. You have until next week to get review from London hotels ;) ! Remember, spiders are python files, but using jupyter notebook can be very useful to try and test.\n",
    "\n",
    "In case of need, here is the [scrapy documentation](https://docs.scrapy.org/en/latest/).\n",
    "\n",
    "Here is how you could proceed :\n",
    "- Open a review page and discover how to parse it\n",
    "- Open a restaurant page and discover how to get reviews urls\n",
    "- Open a restaurant page and discover how to get to next page of reviews\n",
    "- Open a city page and discover how to get restaurant urls\n",
    "- Open a city page and discover how to get the net page of restaurants\n",
    "- Try to put it altogether\n",
    "- Be careful, there a lots of restaurants with a lot of comments\n",
    "\n",
    "But of course you are free to proceed as you want to !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB : To begin, you might want to get only short-description of reviews from restaurant pages and not total review from review pages ;) ! Might be easier to begin !_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seaborn display\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering TripAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin, here are 3 urls that might be useful for you\n",
    "example_url_city = 'https://www.tripadvisor.co.uk/Restaurants-g187147-Paris_Ile_de_France.html'\n",
    "example_url_restaurant = 'https://www.tripadvisor.co.uk/Restaurant_Review-g187147-d9806534-Reviews-ASPIC-Paris_Ile_de_France.html'\n",
    "example_url_review = 'https://www.tripadvisor.co.uk/ShowUserReviews-g187147-d9806534-r731227577-ASPIC-Paris_Ile_de_France.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing selectors in spider perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parsing restaurant list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping finished.\n"
     ]
    }
   ],
   "source": [
    "# Parameters for spider execution\n",
    "file_path = '../scrapped_data/'\n",
    "file_name = 'RestoReview_data.jl'\n",
    "spider_name = 'RestoReviewSpider'\n",
    "path = file_path + file_name\n",
    "\n",
    "# Check if file already exists\n",
    "if file_name in os.listdir(file_path):\n",
    "    _ = os.remove(path)\n",
    "\n",
    "# Execution of spider\n",
    "cmd1 = 'cd ../TA_scrapy/'\n",
    "cmd2 = 'scrapy crawl {} -o {} -a nb_article_max=100'.format(spider_name, path)\n",
    "cmd = cmd1 + ' && ' + cmd2\n",
    "_ = os.system(cmd)\n",
    "\n",
    "if _==0:\n",
    "    print(\"Scrapping finished.\")\n",
    "else:\n",
    "    print('Look at the bash to understand error.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parsing restaurant page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Parsing review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Navigating between pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
